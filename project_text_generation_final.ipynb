{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "oZNHqp5lnxz7",
    "outputId": "40ed06a4-7cf9-47d4-cc69-a7b7ec2e2205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  593k  100  593k    0     0   148k      0  0:00:04  0:00:04 --:--:--  148k98k    0     0  83675      0  0:00:07  0:00:02  0:00:05 83649\n"
     ]
    }
   ],
   "source": [
    "#download the data and save it to poem.txt\n",
    "!curl -o book.txt https://www.gutenberg.org/files/1661/1661-0.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHLcaBBEoLRd"
   },
   "outputs": [],
   "source": [
    "#read the file in text string\n",
    "text = open('book.txt', 'r', encoding='utf-8').read()\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbUq1oKCotPP"
   },
   "outputs": [],
   "source": [
    "#create list of sentences\n",
    "sentences = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CS0-TSEE5RZL",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 19:08:59.727310: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#import dependencies to preprocess the text data and making sequences\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60_eT7er5qhQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#initialize the tokenizer, which can work char by char\n",
    "tokenizer = Tokenizer(oov_token='<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQ-PNcaNAeCW"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3qu1rTY7NCxI",
    "outputId": "1f6b00b8-f929-4325-fa58-53fa0b44f719"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8923"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaFyCfGE-vSi"
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for sequence in sequences:\n",
    "  for i in range(1, len(sequence)):\n",
    "    n_gram_sequence = sequence[:i+1]\n",
    "    input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J5RZLLmsAipB",
    "outputId": "fd6e7f17-7665-4128-a983-5239f8d60aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4776, 158] [4776, 158, 331] [4776, 158, 331, 886] [4776, 158, 331, 886, 5]\n"
     ]
    }
   ],
   "source": [
    "print(input_sequences[0], input_sequences[1], input_sequences[2], input_sequences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-3mHT6TUBApU",
    "outputId": "c2277013-0978-49b0-a0c6-fa23f862f827"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the maximum length among sequences\n",
    "max_seq_len = max([len(seq) for seq in input_sequences])\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJXOYpf3nI0H"
   },
   "outputs": [],
   "source": [
    "#we will keep the last value of the sequence as our target label and all values before that as input to sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8mnnT6nBi5K"
   },
   "outputs": [],
   "source": [
    "#pad the sequences to ensure that they are all of same length\n",
    "padded_sequences = pad_sequences(input_sequences, maxlen = max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "GpvirsLgWPoU",
    "outputId": "96125866-e6c8-4673-f2c2-9ff447b5d60d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0 4776  158] [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0 4776  158  331]\n"
     ]
    }
   ],
   "source": [
    "print(padded_sequences[0], padded_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYhboOBWCLb3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "padded_sequences = np.array(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8BW2NjBcCjLz",
    "outputId": "954f7867-4180-457c-e9c9-89827d349530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(padded_sequences[0]))\n",
    "print(len(padded_sequences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdvK9urMCZXC"
   },
   "outputs": [],
   "source": [
    "#prepare training sequences and labels\n",
    "x = padded_sequences[:, : -1]\n",
    "labels = padded_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zBMmN6-qMqKu",
    "outputId": "649da6da-50ea-41ec-96b1-30f5a846f908"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101523,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvrPC8n5Dw61"
   },
   "outputs": [],
   "source": [
    "#to one hot encode the labels\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ncT36ipmJaqR",
    "outputId": "c5726ee4-105e-4394-bc0f-aa29ab4476d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101523, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIdAL56IcTXW"
   },
   "outputs": [],
   "source": [
    "#x = x.reshape(x.shape[0], x.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dSSjSqj-JXrU",
    "outputId": "bb6b0faf-4a0b-4b12-c31e-cfc30946c80f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101523, 8923)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6H2aOeJGIfG"
   },
   "outputs": [],
   "source": [
    "#import dependencies for defining the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "NKJVkDw8GxCH",
    "outputId": "4c99f965-1eb8-49fa-fb14-63676147d72f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">892,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">731,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8923</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,577,499</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m892,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m731,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8923\u001b[0m)           │     \u001b[38;5;34m4,577,499\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,200,935</span> (23.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,200,935\u001b[0m (23.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,200,935</span> (23.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,200,935\u001b[0m (23.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define and compile the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_seq_len-1))\n",
    "model.add(Bidirectional(LSTM(256)))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "adam = Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "model.build(input_shape=(None, max_seq_len-1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_L_wdid2YzQ"
   },
   "outputs": [],
   "source": [
    "#initialize the callback for early stopping the training if there is not at least 1% improvement in the accuracy \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor = 'acc', min_delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "PAyKsdQtHxkk",
    "outputId": "0a57c835-6cc6-46f0-9f40-a9d9341b17d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 1s/step - acc: 0.0613 - loss: 6.7053\n",
      "Epoch 2/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 1s/step - acc: 0.1406 - loss: 5.3347\n",
      "Epoch 3/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 1s/step - acc: 0.1773 - loss: 4.6877\n",
      "Epoch 4/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 1s/step - acc: 0.2137 - loss: 4.1397\n",
      "Epoch 5/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 1s/step - acc: 0.2589 - loss: 3.6374\n",
      "Epoch 6/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 1s/step - acc: 0.3127 - loss: 3.2038\n",
      "Epoch 7/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 1s/step - acc: 0.3716 - loss: 2.8179\n",
      "Epoch 8/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 1s/step - acc: 0.4260 - loss: 2.5029\n",
      "Epoch 9/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 1s/step - acc: 0.4716 - loss: 2.2558\n",
      "Epoch 10/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 1s/step - acc: 0.5096 - loss: 2.0564\n",
      "Epoch 11/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 1s/step - acc: 0.5393 - loss: 1.9047\n",
      "Epoch 12/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 1s/step - acc: 0.5710 - loss: 1.7565\n",
      "Epoch 13/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 1s/step - acc: 0.5910 - loss: 1.6512\n",
      "Epoch 14/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 1s/step - acc: 0.6128 - loss: 1.5547\n",
      "Epoch 15/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 1s/step - acc: 0.6302 - loss: 1.4637\n",
      "Epoch 16/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 1s/step - acc: 0.6405 - loss: 1.4211\n",
      "Epoch 17/50\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 1s/step - acc: 0.6412 - loss: 1.4080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13f34e250>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=50, verbose=1, batch_size=512, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "sKmppR6VRUwf",
    "outputId": "49d00480-6ce6-41e4-b932-7b8b2d4d11ae",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could not help laughing at the ease with which he explained his process of deduction while i continue to see a crust of metallic deposit all over the tail of the morning and the “g” itself was locked in a one and a bright young man had been driven to the floor in his belief that i could not have been on to my station by end and it is unlikely that the you is a fait to say that the reason why he hears that i have ever seen in my laughter whenever he was kind to do it i am not a very foolish thing out ” he remarked “i think that it\n"
     ]
    }
   ],
   "source": [
    "#Time to become storyteller!\n",
    "seed_text = \"I could not help laughing at the ease with which he explained his process of deduction\"          \n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "  sequence = tokenizer.texts_to_sequences([seed_text])\n",
    "  padded = pad_sequences(sequence, maxlen=max_seq_len-1)\n",
    "  predicted_prob = model.predict(padded, verbose=0)\n",
    "  predicted_class = np.argmax(predicted_prob, axis=-1)[0]\n",
    "    \n",
    "  output_word = ''\n",
    "  for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted_class:\n",
    "      output_word = word\n",
    "      break\n",
    "  seed_text += ' ' + output_word\n",
    "print(seed_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "project_text_generation_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
